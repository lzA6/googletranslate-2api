é¡¹ç›® 'googletranslate-2api' çš„ç»“æ„æ ‘:
ğŸ“‚ googletranslate-2api/
    ğŸ“„ .env
    ğŸ“„ .env.example
    ğŸ“„ Dockerfile
    ğŸ“„ docker-compose.yml
    ğŸ“„ main.py
    ğŸ“„ nginx.conf
    ğŸ“„ requirements.txt
    ğŸ“‚ app/
        ğŸ“‚ core/
            ğŸ“„ __init__.py
            ğŸ“„ config.py
        ğŸ“‚ providers/
            ğŸ“„ __init__.py
            ğŸ“„ base_provider.py
            ğŸ“„ googletranslate_provider.py
        ğŸ“‚ utils/
            ğŸ“„ sse_utils.py
================================================================================

--- æ–‡ä»¶è·¯å¾„: .env ---

API_MASTER_KEY=1

# --- éƒ¨ç½²é…ç½® (å¯é€‰) ---
# Nginx å¯¹å¤–æš´éœ²çš„ç«¯å£
NGINX_PORT=8088

# --- Google Translate å‡­è¯ (å¿…é¡»è®¾ç½®) ---
# è¯·ä»æµè§ˆå™¨å¼€å‘è€…å·¥å…·çš„ç½‘ç»œè¯·æ±‚ä¸­æ‰¾åˆ° `translateHtml` è¯·æ±‚ï¼Œ
# å¹¶å¤åˆ¶å…¶è¯·æ±‚å¤´ä¸­çš„ `x-goog-api-key` å€¼ã€‚
GOOGLE_API_KEY="AIzaSyATBXajvzQLTDHEQbcpq0Ihe0vWDHmO520"

--- æ–‡ä»¶è·¯å¾„: .env.example ---

# ====================================================================
# googletranslate-2api é…ç½®æ–‡ä»¶æ¨¡æ¿
# ====================================================================
#
# è¯·å°†æ­¤æ–‡ä»¶é‡å‘½åä¸º ".env" å¹¶å¡«å…¥æ‚¨çš„å‡­è¯ã€‚
#

# --- æ ¸å¿ƒå®‰å…¨é…ç½® (å¿…é¡»è®¾ç½®) ---
# ç”¨äºä¿æŠ¤æ‚¨ API æœåŠ¡çš„è®¿é—®å¯†é’¥ã€‚
API_MASTER_KEY=sk-googletranslate-2api-default-key-please-change-me

# --- éƒ¨ç½²é…ç½® (å¯é€‰) ---
# Nginx å¯¹å¤–æš´éœ²çš„ç«¯å£
NGINX_PORT=8088

# --- Google Translate å‡­è¯ (å¿…é¡»è®¾ç½®) ---
# è¯·ä»æµè§ˆå™¨å¼€å‘è€…å·¥å…·çš„ç½‘ç»œè¯·æ±‚ä¸­æ‰¾åˆ° `translateHtml` è¯·æ±‚ï¼Œ
# å¹¶å¤åˆ¶å…¶è¯·æ±‚å¤´ä¸­çš„ `x-goog-api-key` å€¼ã€‚
GOOGLE_API_KEY="AIzaSyATBXajvzQLTDHEQbcpq0Ihe0vWDHmO520"


--- æ–‡ä»¶è·¯å¾„: Dockerfile ---

# ====================================================================
# Dockerfile for googletranslate-2api (v1.0 - Chimera Synthesis)
# ====================================================================

FROM python:3.10-slim

# è®¾ç½®ç¯å¢ƒå˜é‡
ENV PYTHONDONTWRITEBYTECODE=1
ENV PYTHONUNBUFFERED=1
WORKDIR /app

# å®‰è£… Python ä¾èµ–
COPY requirements.txt .
RUN pip install --no-cache-dir --upgrade pip && \
    pip install --no-cache-dir -r requirements.txt

# å¤åˆ¶åº”ç”¨ä»£ç 
COPY . .

# åˆ›å»ºå¹¶åˆ‡æ¢åˆ°é root ç”¨æˆ·
RUN useradd --create-home appuser && \
    chown -R appuser:appuser /app
USER appuser

# æš´éœ²ç«¯å£å¹¶å¯åŠ¨
EXPOSE 8000
CMD ["uvicorn", "main:app", "--host", "0.0.0.0", "--port", "8000", "--workers", "1"]


--- æ–‡ä»¶è·¯å¾„: docker-compose.yml ---

services:
  nginx:
    image: nginx:latest
    container_name: googletranslate-2api-nginx
    restart: always
    ports:
      - "${NGINX_PORT:-8088}:80"
    volumes:
      - ./nginx.conf:/etc/nginx/nginx.conf:ro
    depends_on:
      - app
    networks:
      - googletranslate-net

  app:
    build:
      context: .
      dockerfile: Dockerfile
    container_name: googletranslate-2api-app
    restart: unless-stopped
    env_file:
      - .env
    networks:
      - googletranslate-net

networks:
  googletranslate-net:
    driver: bridge


--- æ–‡ä»¶è·¯å¾„: main.py ---

import sys
from contextlib import asynccontextmanager
from typing import Optional

from fastapi import FastAPI, Request, HTTPException, Depends, Header
from fastapi.responses import JSONResponse, StreamingResponse
from loguru import logger

from app.core.config import settings
from app.providers.googletranslate_provider import GoogleTranslateProvider

# --- é…ç½® Loguru ---
logger.remove()
logger.add(
    sys.stdout,
    level="INFO",
    format="<green>{time:YYYY-MM-DD HH:mm:ss.SSS}</green> | "
           "<level>{level: <8}</level> | "
           "<cyan>{name}</cyan>:<cyan>{function}</cyan>:<cyan>{line}</cyan> - <level>{message}</level>",
    colorize=True
)

# --- å…¨å±€ Provider å®ä¾‹ ---
provider = GoogleTranslateProvider()

@asynccontextmanager
async def lifespan(app: FastAPI):
    logger.info(f"åº”ç”¨å¯åŠ¨ä¸­... {settings.APP_NAME} v{settings.APP_VERSION}")
    await provider.initialize()
    logger.info(f"æœåŠ¡å°†åœ¨ http://localhost:{settings.NGINX_PORT} ä¸Šå¯ç”¨")
    yield
    await provider.close()
    logger.info("åº”ç”¨å…³é—­ã€‚")

app = FastAPI(
    title=settings.APP_NAME,
    version=settings.APP_VERSION,
    description=settings.DESCRIPTION,
    lifespan=lifespan
)

# --- å®‰å…¨ä¾èµ– ---
async def verify_api_key(authorization: Optional[str] = Header(None)):
    if settings.API_MASTER_KEY and settings.API_MASTER_KEY != "1":
        if not authorization or "bearer" not in authorization.lower():
            raise HTTPException(status_code=401, detail="éœ€è¦ Bearer Token è®¤è¯ã€‚")
        token = authorization.split(" ")[-1]
        if token != settings.API_MASTER_KEY:
            raise HTTPException(status_code=403, detail="æ— æ•ˆçš„ API Keyã€‚")

# --- API è·¯ç”± ---
@app.post("/v1/chat/completions", dependencies=[Depends(verify_api_key)])
async def chat_completions(request: Request):
    try:
        request_data = await request.json()
        return await provider.chat_completion(request_data)
    except Exception as e:
        logger.error(f"å¤„ç†èŠå¤©è¯·æ±‚æ—¶å‘ç”Ÿé¡¶å±‚é”™è¯¯: {e}", exc_info=True)
        raise HTTPException(status_code=500, detail=f"å†…éƒ¨æœåŠ¡å™¨é”™è¯¯: {str(e)}")

@app.get("/v1/models", dependencies=[Depends(verify_api_key)])
async def list_models():
    return await provider.get_models()

@app.get("/", summary="æ ¹è·¯å¾„", include_in_schema=False)
def root():
    return {"message": f"æ¬¢è¿æ¥åˆ° {settings.APP_NAME} v{settings.APP_VERSION}. æœåŠ¡è¿è¡Œæ­£å¸¸ã€‚"}


--- æ–‡ä»¶è·¯å¾„: nginx.conf ---

worker_processes auto;

events {
    worker_connections 1024;
}

http {
    upstream googletranslate_backend {
        # API æ˜¯æ— çŠ¶æ€çš„ï¼Œæ— éœ€ ip_hash
        server app:8000;
    }

    server {
        listen 80;
        server_name localhost;

        location / {
            proxy_pass http://googletranslate_backend;
            proxy_set_header Host $host;
            proxy_set_header X-Real-IP $remote_addr;
            proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
            proxy_set_header X-Forwarded-Proto $scheme;
            
            # æµå¼ä¼ è¾“ä¼˜åŒ–
            proxy_buffering off;
            proxy_cache off;
            proxy_set_header Connection '';
            proxy_http_version 1.1;
            chunked_transfer_encoding off;
        }
    }
}


--- æ–‡ä»¶è·¯å¾„: requirements.txt ---

fastapi
uvicorn[standard]
httpx
pydantic-settings
python-dotenv
loguru
beautifulsoup4
markdownify


--- æ–‡ä»¶è·¯å¾„: app\core\__init__.py ---



--- æ–‡ä»¶è·¯å¾„: app\core\config.py ---

from pydantic_settings import BaseSettings, SettingsConfigDict
from typing import Optional, List

class Settings(BaseSettings):
    model_config = SettingsConfigDict(
        env_file=".env",
        env_file_encoding='utf-8',
        extra="ignore"
    )

    APP_NAME: str = "googletranslate-2api"
    APP_VERSION: str = "1.0.0"
    DESCRIPTION: str = "ä¸€ä¸ªå°† Google Translate API è½¬æ¢ä¸ºå…¼å®¹ OpenAI æ ¼å¼çš„ä»£ç†ã€‚"

    API_MASTER_KEY: Optional[str] = None
    NGINX_PORT: int = 8088
    
    GOOGLE_API_KEY: Optional[str] = None

    API_REQUEST_TIMEOUT: int = 60

    DEFAULT_MODEL: str = "google-translate"
    KNOWN_MODELS: List[str] = ["google-translate"]

settings = Settings()


--- æ–‡ä»¶è·¯å¾„: app\providers\__init__.py ---



--- æ–‡ä»¶è·¯å¾„: app\providers\base_provider.py ---

from abc import ABC, abstractmethod
from typing import Dict, Any
from fastapi.responses import StreamingResponse, JSONResponse

class BaseProvider(ABC):
    @abstractmethod
    async def chat_completion(self, request_data: Dict[str, Any]) -> StreamingResponse:
        pass

    @abstractmethod
    async def get_models(self) -> JSONResponse:
        pass


--- æ–‡ä»¶è·¯å¾„: app\providers\googletranslate_provider.py ---

import httpx
import json
import time
import uuid
import re
from typing import Dict, Any, AsyncGenerator, Optional

from fastapi import HTTPException
from fastapi.responses import StreamingResponse, JSONResponse
from loguru import logger
from markdownify import markdownify as md
from bs4 import BeautifulSoup

from app.core.config import settings
from app.providers.base_provider import BaseProvider
from app.utils.sse_utils import create_sse_data, create_chat_completion_chunk, DONE_CHUNK

class GoogleTranslateProvider(BaseProvider):
    BASE_URL = "https://translate-pa.googleapis.com/v1/translateHtml"
    CHINESE_REGEX = re.compile(r'[\u4e00-\u9fa5]')

    def __init__(self):
        self.client: Optional[httpx.AsyncClient] = None

    async def initialize(self):
        if not settings.GOOGLE_API_KEY:
            raise ValueError("GOOGLE_API_KEY æœªåœ¨ .env æ–‡ä»¶ä¸­é…ç½®ã€‚")
        self.client = httpx.AsyncClient(timeout=settings.API_REQUEST_TIMEOUT)

    async def close(self):
        if self.client:
            await self.client.aclose()

    async def chat_completion(self, request_data: Dict[str, Any]) -> StreamingResponse:
        
        async def stream_generator() -> AsyncGenerator[bytes, None]:
            request_id = f"chatcmpl-{uuid.uuid4()}"
            model_name = request_data.get("model", settings.DEFAULT_MODEL)
            
            try:
                headers = self._prepare_headers()
                payload = self._prepare_payload(request_data)
                
                logger.info(f"å‘ä¸Šæ¸¸å‘é€ç¿»è¯‘è¯·æ±‚: {payload}")
                
                response = await self.client.post(self.BASE_URL, headers=headers, json=payload)
                
                logger.info(f"ä¸Šæ¸¸å“åº”çŠ¶æ€ç : {response.status_code}")
                response.raise_for_status()
                
                response_data = response.json()
                logger.info(f"æ”¶åˆ°ä¸Šæ¸¸å“åº”: {response_data}")

                # --- å¥å£®çš„å“åº”è§£æé€»è¾‘ (å·²ä¿®æ”¹) ---
                translated_html = ""
                if isinstance(response_data, list) and response_data:
                    if isinstance(response_data[0], list) and response_data[0]:
                        # æ­£å¸¸æƒ…å†µï¼Œè·å–ç¿»è¯‘åçš„ HTML
                        translated_html = response_data[0][0]
                elif not isinstance(response_data, list):
                    # å¦‚æœå“åº”ä¸æ˜¯åˆ—è¡¨ï¼Œåˆ™ä¸ºå¼‚å¸¸æƒ…å†µ
                    raise ValueError(f"ä¸Šæ¸¸å“åº”æ ¼å¼ä¸ç¬¦åˆé¢„æœŸ: {response_data}")
                # å¦‚æœ response_data æ˜¯ç©ºåˆ—è¡¨ `[]`ï¼Œåˆ™ translated_html ä¿æŒä¸ºç©ºå­—ç¬¦ä¸²ï¼Œè¿™æ˜¯æ­£å¸¸æƒ…å†µ

                # --- å¢å¼ºçš„æ–‡æœ¬æ¸…ç† ---
                soup = BeautifulSoup(translated_html, 'html.parser')
                clean_text = soup.get_text()
                # ç§»é™¤é›¶å®½ç©ºæ ¼ç­‰ä¸å¯è§å­—ç¬¦
                clean_text = clean_text.replace('\u200b', '')

                # å°†æ¸…ç†åçš„æ–‡æœ¬è½¬æ¢ä¸º Markdown
                markdown_text = md(clean_text)

                # å‘é€åŒ…å«å®Œæ•´ç¿»è¯‘ç»“æœçš„å•ä¸ªæ•°æ®å—
                chunk = create_chat_completion_chunk(request_id, model_name, markdown_text)
                yield create_sse_data(chunk)
                
                # å‘é€ç»“æŸæ ‡å¿—
                final_chunk = create_chat_completion_chunk(request_id, model_name, "", "stop")
                yield create_sse_data(final_chunk)
                yield DONE_CHUNK

            except Exception as e:
                logger.error(f"å¤„ç†ç¿»è¯‘è¯·æ±‚æ—¶å‘ç”Ÿé”™è¯¯: {e}", exc_info=True)
                error_message = f"å†…éƒ¨æœåŠ¡å™¨é”™è¯¯: {str(e)}"
                error_chunk = create_chat_completion_chunk(request_id, model_name, error_message, "stop")
                yield create_sse_data(error_chunk)
                yield DONE_CHUNK

        return StreamingResponse(stream_generator(), media_type="text/event-stream")

    def _prepare_headers(self) -> Dict[str, str]:
        # (å·²ä¿®æ”¹) æ·»åŠ äº† User-Agent æ¥æ¨¡æ‹ŸçœŸå®æµè§ˆå™¨è¯·æ±‚
        return {
            "Accept": "*/*",
            "Accept-Language": "zh-CN,zh;q=0.9,en;q=0.8",
            "Content-Type": "application/json+protobuf",
            "Origin": "https://stackoverflow.ai",
            "Referer": "https://stackoverflow.ai/",
            "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/141.0.0.0 Safari/537.36",
            "x-goog-api-key": settings.GOOGLE_API_KEY,
        }

    def _prepare_payload(self, request_data: Dict[str, Any]) -> list:
        messages = request_data.get("messages", [])
        if not messages or messages[-1].get("role") != "user":
            raise HTTPException(status_code=400, detail="è¯·æ±‚ä¸­ç¼ºå°‘æœ‰æ•ˆçš„ç”¨æˆ·æ¶ˆæ¯ã€‚")
        
        content = messages[-1]["content"]
        # å¦‚æœ content ä¸ºç©ºæˆ– Noneï¼ŒAPI å¯èƒ½ä¼šè¿”å›é”™è¯¯æˆ–ç©ºå†…å®¹ï¼Œè¿™é‡Œæˆ‘ä»¬å°†å…¶è§†ä¸ºç©ºå­—ç¬¦ä¸²
        text_to_translate = content if content is not None else ""
        
        # æ™ºèƒ½è¯­è¨€è·¯ç”±é€»è¾‘
        source_lang = request_data.get("source_lang", "auto")
        target_lang = request_data.get("target_lang")

        if not target_lang:
            # å¦‚æœç”¨æˆ·æœªæŒ‡å®šç›®æ ‡è¯­è¨€ï¼Œåˆ™è‡ªåŠ¨åˆ¤æ–­
            if self.CHINESE_REGEX.search(text_to_translate):
                target_lang = "en" # è¾“å…¥æ˜¯ä¸­æ–‡ï¼Œé»˜è®¤ç¿»è¯‘æˆè‹±æ–‡
                logger.info("æ£€æµ‹åˆ°ä¸­æ–‡è¾“å…¥ï¼Œè‡ªåŠ¨è®¾ç½®ç›®æ ‡è¯­è¨€ä¸º 'en'")
            else:
                target_lang = "zh-CN" # è¾“å…¥æ˜¯å…¶ä»–è¯­è¨€ï¼Œé»˜è®¤ç¿»è¯‘æˆä¸­æ–‡
                logger.info("æœªæ£€æµ‹åˆ°ä¸­æ–‡è¾“å…¥ï¼Œè‡ªåŠ¨è®¾ç½®ç›®æ ‡è¯­è¨€ä¸º 'zh-CN'")
        
        return [
            [[text_to_translate], source_lang, target_lang],
            "te_lib"
        ]

    async def get_models(self) -> JSONResponse:
        model_data = {
            "object": "list",
            "data": [
                {"id": name, "object": "model", "created": int(time.time()), "owned_by": "lzA6"}
                for name in settings.KNOWN_MODELS
            ]
        }
        return JSONResponse(content=model_data)


--- æ–‡ä»¶è·¯å¾„: app\utils\sse_utils.py ---

import json
import time
from typing import Dict, Any, Optional

DONE_CHUNK = b"data: [DONE]\n\n"

def create_sse_data(data: Dict[str, Any]) -> bytes:
    """å°†å­—å…¸æ•°æ®æ ¼å¼åŒ–ä¸º SSE äº‹ä»¶å­—ç¬¦ä¸²ã€‚"""
    return f"data: {json.dumps(data)}\n\n".encode('utf-8')

def create_chat_completion_chunk(
    request_id: str,
    model: str,
    content: str,
    finish_reason: Optional[str] = None
) -> Dict[str, Any]:
    """
    åˆ›å»ºä¸€ä¸ªä¸ OpenAI å…¼å®¹çš„èŠå¤©è¡¥å…¨æµå¼å—ã€‚
    """
    return {
        "id": request_id,
        "object": "chat.completion.chunk",
        "created": int(time.time()),
        "model": model,
        "choices": [
            {
                "index": 0,
                "delta": {"content": content},
                "finish_reason": finish_reason
            }
        ]
    }



